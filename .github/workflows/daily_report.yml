name: Daily StonkzzReport

on:
  schedule:
    # 01:30 UTC = 07:00 AM IST (Pre-market briefing)
    # Runs Monday to Friday only
    - cron: '30 1 * * 1-5'
  workflow_dispatch:
    # Allow manual trigger for testing

jobs:
  generate-and-email-report:
    runs-on: ubuntu-latest
    
    steps:
      # 1. Checkout repository
      - name: Checkout Code
        uses: actions/checkout@v4

      # 2. Setup Python 3.11
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # 3. Setup Node.js 18
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      # 4. Install Backend Dependencies
      - name: Install Backend Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r backend/requirements.txt

      # 5. Install Playwright (CRITICAL for PDF generation)
      - name: Install Playwright Chromium
        run: |
          pip install playwright
          playwright install chromium
          playwright install-deps chromium

      # 6. Install Frontend Dependencies
      - name: Install Frontend Dependencies
        run: |
          cd frontend
          npm install

      # 7. Inject Secrets into .env file
      - name: Create Backend .env File
        run: |
          echo "GROQ_API_KEY=${{ secrets.GROQ_API_KEY }}" >> backend/.env
          echo "TWELVE_DATA_KEY=${{ secrets.TWELVE_DATA_KEY }}" >> backend/.env
          echo "NEWS_API_KEY=${{ secrets.NEWS_API_KEY }}" >> backend/.env
          echo "EMAIL_SENDER=${{ secrets.EMAIL_SENDER }}" >> backend/.env
          echo "EMAIL_APP_PASSWORD=${{ secrets.EMAIL_APP_PASSWORD }}" >> backend/.env
          echo "EMAIL_RECIPIENTS=${{ secrets.EMAIL_RECIPIENTS }}" >> backend/.env
          echo "EMAIL_ENABLED=true" >> backend/.env

      # 8. Fetch Market Data
      - name: Fetch Market Data
        run: |
          cd backend
          python fetch_data_v3.py
        continue-on-error: true  # Continue even if some data sources fail

      # 8.5. Validate Data Freshness
      - name: Validate Data Freshness
        run: |
          python - <<EOF
          import os
          import json
          from datetime import datetime
          try:
              from zoneinfo import ZoneInfo
              # Use IST timezone for consistency with data generation
              timezone = ZoneInfo("Asia/Kolkata")
              use_timezone = True
          except ImportError:
              # Fallback to naive datetime if zoneinfo not available
              timezone = None
              use_timezone = False

          print("\n" + "="*70)
          print("DATA FRESHNESS VALIDATION")
          print("="*70 + "\n")

          data_files = [
              'frontend/public/Data/gift_nifty.json',
              'frontend/public/Data/nifty_data.json',
              'frontend/public/Data/fii_dii_data.json'
          ]

          stale_files = []
          for file_path in data_files:
              if os.path.exists(file_path):
                  try:
                      with open(file_path, 'r') as f:
                          data = json.load(f)
                          
                          timestamp_str = data.get('timestamp', '')
                          if timestamp_str:
                              # Parse timestamp without timezone
                              timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
                              
                              # Make timezone-aware for accurate comparison
                              if use_timezone:
                                  timestamp = timestamp.replace(tzinfo=timezone)
                                  now = datetime.now(timezone)
                              else:
                                  now = datetime.now()
                              
                              age_hours = (now - timestamp).total_seconds() / 3600
                              
                              print(f"üìä {file_path}")
                              print(f"   Timestamp: {timestamp_str}")
                              print(f"   Age: {age_hours:.1f} hours")
                              
                              if age_hours > 24:
                                  print(f"   ‚ö†Ô∏è WARNING: Data is STALE (>24h)")
                                  stale_files.append((file_path, age_hours))
                              else:
                                  print(f"   ‚úÖ Data is fresh")
                              print()
                  except Exception as e:
                      print(f"‚ùå Error checking {file_path}: {e}\n")

          if stale_files:
              print("="*70)
              print("‚ö†Ô∏è STALE DATA DETECTED:")
              for file_path, age in stale_files:
                  print(f"  - {file_path}: {age:.1f} hours old")
              print("="*70)
              exit(1)  # Fail the workflow if critical data is stale
          else:
              print("="*70)
              print("‚úÖ All data files are fresh")
              print("="*70)
          EOF
        continue-on-error: false  # Make this a hard failure

      # 9. Generate PDF Report and Send Email
      - name: Generate PDF and Send Email
        run: |
          python generate_pdf_report.py

      # 10. Upload PDF as Artifact (Safety Net)
      - name: Upload PDF Artifact
        uses: actions/upload-artifact@v4
        if: always()  # Upload even if previous steps fail
        with:
          name: stonkzz-report-${{ github.run_number }}
          path: generated_reports/*.pdf
          retention-days: 7
          if-no-files-found: warn
